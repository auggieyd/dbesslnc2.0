{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Convert GTF files to custom BED files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_attribute(attr_str, key):\n",
    "    match = re.search(f'{key} \"([^\"]+)\"', attr_str)\n",
    "    return match.group(1) if match else \"N.A.\"\n",
    "\n",
    "def convert_gtf_to_bed(input_gtf, output_file):\n",
    "    \"\"\"\n",
    "    Convert GTF file to BED format.\n",
    "    \"\"\"\n",
    "    with open(input_gtf, 'r') as f_in, open(output_file, 'w') as f_out:\n",
    "        for line in f_in:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 9:\n",
    "                continue\n",
    "\n",
    "            # annotations\n",
    "            chr_name = fields[0]\n",
    "            start = str(int(fields[3]) - 1)  \n",
    "            end = fields[4]\n",
    "            score = '.'\n",
    "            strand = fields[6]\n",
    "            feature_type = fields[2]\n",
    "            attributes = fields[8]\n",
    "\n",
    "\n",
    "            gene_id = extract_attribute(attributes, 'gene_id')\n",
    "            transcript_id = extract_attribute(attributes, 'transcript_id')\n",
    "            gene_name = extract_attribute(attributes, 'gene_name')\n",
    "\n",
    "\n",
    "            id_field = gene_id if feature_type == 'gene' else transcript_id\n",
    "\n",
    "            bed_line = f\"{chr_name}\\t{start}\\t{end}\\t{id_field}\\t{score}\\t{strand}\\t{gene_id}\\t{feature_type}\\t{gene_name}\\n\"\n",
    "            f_out.write(bed_line)\n",
    "if __name__ == \"__main__\":\n",
    "   convert_gtf_to_bed(\"./test/gencode.v47.long_noncoding_RNAs.gtf\", \"./test/output/gencodev47.bed\")\n",
    "   convert_gtf_to_bed(\"./test/NONCODEv6_human_hg38_lncRNA.gtf\", \"./test/output/noncode.bed\")\n",
    "   convert_gtf_to_bed(\"./test/lncRNA_LncBookv2.0_GRCh38.gtf\", \"./test/output/lncbook.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NCBI GTF, we use a specific script to handle the lncRNA-only conversion\n",
    "!python3 conBed.py ./test/GCF_000001405.40_GRCh38.p14_genomic.gtf ./test/output/ncbi.bed --lncrna-only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1.1: Generate files for subsequent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auggi\\AppData\\Local\\Temp\\ipykernel_32032\\2863546523.py:16: DtypeWarning: Columns (1,2,4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(bed_file, sep='\\t', header=None, names=['chr', 'start', 'end', 'name', 'score', 'strand', 'gene_id','transcript_id', 'gene_type', 'gene_name','gene_biotype','GeneID'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def convert_bed_to_gene_mapping(bed_file):\n",
    "    \"\"\"\n",
    "    Convert BED file to gene mapping format.\n",
    "    \"\"\"\n",
    "    with open(bed_file) as f:\n",
    "        first_line = f.readline()\n",
    "        num_columns = len(first_line.strip().split('\\t'))\n",
    "\n",
    "    # Select column names based on column count\n",
    "    if num_columns == 9:\n",
    "        col_names = ['chr', 'start', 'end', 'trans_id', 'score', 'strand', 'GeneID', 'gene_type', 'gene_name']\n",
    "        df = pd.read_csv(bed_file, sep='\\t', header=None, names=col_names)\n",
    "    elif num_columns == 12:\n",
    "        col_names = ['chr', 'start', 'end', 'name', 'score', 'strand', 'gene_id', 'transcript_id', 'feature', 'gene_name', 'gene_biotype', 'GeneID']\n",
    "        df = pd.read_csv(bed_file, sep='\\t', header=None, names=['chr', 'start', 'end', 'name', 'score', 'strand', 'gene_id','transcript_id', 'gene_type', 'gene_name','gene_biotype','GeneID'])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected number of columns: {num_columns}\")\n",
    "    \n",
    "    # df['gene_name'] = df['gene_name']\n",
    "    \n",
    "\n",
    "    mask = (df['gene_type'] == 'gene') & (df['gene_name'] != 'N.A.'& df['gene_name'])\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    result_df = filtered_df[['gene_name', 'GeneID']]\n",
    "    result_df.to_csv('gene_mapping.txt', sep='\\t', mode='a', index=False, header=False)\n",
    "convert_bed_to_gene_mapping('./test/output/lncbook.bed')\n",
    "convert_bed_to_gene_mapping('./test/output/ncbi.bed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2:Map public database gene IDs and other annotation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('bedtools intersect -a ./test/output/crispr_all.bed -b ./test/output/lncbook.bed -wo -s -r -f 1 > ./test/output/lctemp.bed')\n",
    "os.system('bedtools intersect -a ./test/output/crispr_all.bed -b ./test/output/noncode.bed -wo -s -r -f 1 > ./test/output/nctemp.bed')\n",
    "os.system('bedtools intersect -a ./test/output/crispr_all.bed -b ./test/output/gencodev47.bed -wo -s -r -f 1 > ./test/output/gctemp.bed')\n",
    "os.system('bedtools intersect -a ./test/output/crispr_all.bed -b ./test/output/ncbi.bed -wo -s -r -f 1 > ./test/output/nbtemp.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the temporary BED file to generate a TSV file; remove duplicates by cumulative overlapping length\n",
    "from collections import defaultdict\n",
    "import os\n",
    "def bed2tsv(input_temp_bed_file, result_file):\n",
    "    \"\"\"\n",
    "    Convert a temporary BED file to a TSV file with specific fields.\n",
    "    \"\"\"\n",
    "     # \n",
    "    primary_groups = defaultdict(lambda: defaultdict(dict))\n",
    "    sums = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "\n",
    "    with open(input_temp_bed_file, 'r') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) >= 16:  \n",
    "                key = fields[3].rsplit('-', 1)[0]\n",
    "                gene_id = fields[12]\n",
    "                length = int(fields[15])\n",
    "                transcript_id = fields[3].rsplit('-', 1)[1]\n",
    "\n",
    "\n",
    "                col8 = fields[7]\n",
    "                col9 = fields[8]\n",
    "                deduplicate_key = (col8, col9)  \n",
    "\n",
    "                value = (transcript_id, fields[9], fields[12], fields[14], fields[13])\n",
    "\n",
    "\n",
    "                if deduplicate_key not in primary_groups[key][gene_id]:\n",
    "                \n",
    "                    primary_groups[key][gene_id][deduplicate_key] = value\n",
    "\n",
    "                    sums[key][gene_id] += length\n",
    "\n",
    "\n",
    "    with open('temp.tsv', 'w') as out:\n",
    "        for key, gene_groups in primary_groups.items():\n",
    "\n",
    "            if len(gene_groups) > 1:\n",
    "\n",
    "                max_gene_id = max(gene_groups.keys(), key=lambda x: sums[key][x])\n",
    "\n",
    "                for record in gene_groups[max_gene_id].values():\n",
    "                    out.write(key+'\\t'+'\\t'.join(record) + '\\n')\n",
    "            else:\n",
    "\n",
    "                for records in gene_groups.values():\n",
    "                    for record in records.values():\n",
    "                        out.write(key+'\\t'+'\\t'.join(record) + '\\n')\n",
    "\n",
    "    os.system('sort temp.tsv | uniq > ' + result_file)\n",
    "if __name__ == \"__main__\":\n",
    "    bed2tsv(\"./test/output/gctemp.bed\", \"./test/map/gencode_map.tsv\")\n",
    "    bed2tsv(\"./test/output/lctemp.bed\", \"./test/map/lncbook_map.tsv\")\n",
    "    bed2tsv(\"./test/output/nctemp.bed\", \"./test/map/noncode_map.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in new match data: 85358\n",
      "Number of new targets: 356\n",
      "Checking gene_id conflicts, only handling LOC/non-LOC mixed conflicts...\n",
      "Handled 7 LOC/non-LOC mixed conflicts\n",
      "✓ LOC conflict resolution report saved: loc_gene_conflict_resolution.csv\n",
      "Calculating best gene mapping for each target (based on deduplicated exon cumulative length)...\n",
      "Number of target-gene combinations: 362\n",
      "✓ output: ./test/map/ncbi_map.tsv\n"
     ]
    }
   ],
   "source": [
    "#for NCBI bed\n",
    "!python3 pro1.py ./test/output/nbtemp.bed ./test/map/ncbi_map.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ./test/map/noncode_map.tsv:\n",
      "  Excluded genes: 860\n",
      "  Output lines in filtered_noncode_crispr.bed: 1640\n",
      "\n",
      "Processed ./test/map/lncbook_map.tsv:\n",
      "  Excluded genes: 1015\n",
      "  Output lines in filtered_lncbook_crispr.bed: 1382\n",
      "\n",
      "Processed ./test/map/gencode_map.tsv:\n",
      "  Excluded genes: 760\n",
      "  Output lines in filtered_gencode_crispr.bed: 2729\n",
      "\n",
      "Processed ./test/map/ncbi_map.tsv:\n",
      "  Excluded genes: 356\n",
      "  Output lines in filtered_ncbi_crispr.bed: 7126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define mapping between TSV files and their output BED files\n",
    "tsv_to_bed = {\n",
    "    './test/map/noncode_map.tsv': 'filtered_noncode_crispr.bed',\n",
    "    './test/map/lncbook_map.tsv': 'filtered_lncbook_crispr.bed',\n",
    "    './test/map/gencode_map.tsv': 'filtered_gencode_crispr.bed',\n",
    "    './test/map/ncbi_map.tsv': 'filtered_ncbi_crispr.bed'\n",
    "}\n",
    "\n",
    "# Process each TSV file individually\n",
    "for tsv_file, output_bed in tsv_to_bed.items():\n",
    "    # Collect unique genes from first column of current TSV file\n",
    "    exclude_genes = set()\n",
    "    with open(tsv_file, 'r') as f:\n",
    "    # Get unique genes from first column\n",
    "        exclude_genes = set(line.split('\\t')[0] for line in f)\n",
    "    \n",
    "    # Filter crispr_all.bed based on current exclusion list\n",
    "    filtered_lines = []\n",
    "    with open('./test/output/crispr_all.bed', 'r') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if not fields:  # Skip empty lines\n",
    "                continue\n",
    "            \n",
    "            # Extract gene name (part before last \"-\" in 4th column)\n",
    "            try:\n",
    "                gene_name = fields[3].rsplit('-', 1)[0]\n",
    "            except IndexError:\n",
    "                # Handle lines without \"-\" in 4th column\n",
    "                gene_name = fields[3]\n",
    "            \n",
    "            # Keep line if gene not in current exclusion set\n",
    "            if gene_name not in exclude_genes:\n",
    "                filtered_lines.append(line)\n",
    "    \n",
    "    # Write filtered results to corresponding output file\n",
    "    with open(output_bed, 'w') as f:\n",
    "        f.writelines(filtered_lines)\n",
    "    \n",
    "    # Print statistics for current processing step\n",
    "    print(f\"Processed {tsv_file}:\")\n",
    "    print(f\"  Excluded genes: {len(exclude_genes)}\")\n",
    "    print(f\"  Output lines in {output_bed}: {len(filtered_lines)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for gene entries where one exon is completely contained within another exon.\n",
    "!bedtools intersect -a filtered_lncbook_crispr.bed -b ./test/output/lncbook.bed -wo -s -f 1 > res_lctemp.bed\n",
    "!bedtools intersect -a filtered_noncode_crispr.bed -b ./test/output/noncode.bed -wo -s -f 1 > res_nctemp.bed\n",
    "!bedtools intersect -a filtered_gencode_crispr.bed -b ./test/output/gencodev47.bed -wo -s -f 1 > res_gctemp.bed\n",
    "!bedtools intersect -a filtered_ncbi_crispr.bed -b ./test/output/ncbi.bed -wo -s -f 1 > res_nbtemp.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the temporary BED file to generate a TSV file; remove duplicates by cumulative overlapping length\n",
    "from collections import defaultdict\n",
    "import os\n",
    "def bed2tsv(input_temp_bed_file, result_file):\n",
    "    \"\"\"\n",
    "    Convert a temporary BED file to a TSV file with specific fields.\n",
    "    \"\"\"\n",
    "     # \n",
    "    primary_groups = defaultdict(lambda: defaultdict(dict))\n",
    "    sums = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "\n",
    "    with open(input_temp_bed_file, 'r') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) >= 16:  \n",
    "                key = fields[3].rsplit('-', 1)[0]\n",
    "                gene_id = fields[12]\n",
    "                length = int(fields[15])\n",
    "                transcript_id = fields[3].rsplit('-', 1)[1]\n",
    "\n",
    "\n",
    "                col8 = fields[7]\n",
    "                col9 = fields[8]\n",
    "                deduplicate_key = (col8, col9)  \n",
    "\n",
    "                value = (transcript_id, fields[9], fields[12], fields[14], fields[13])\n",
    "\n",
    "\n",
    "                if deduplicate_key not in primary_groups[key][gene_id]:\n",
    "                \n",
    "                    primary_groups[key][gene_id][deduplicate_key] = value\n",
    "\n",
    "                    sums[key][gene_id] += length\n",
    "\n",
    "\n",
    "    with open('temp.tsv', 'w') as out:\n",
    "        for key, gene_groups in primary_groups.items():\n",
    "\n",
    "            if len(gene_groups) > 1:\n",
    "\n",
    "                max_gene_id = max(gene_groups.keys(), key=lambda x: sums[key][x])\n",
    "\n",
    "                for record in gene_groups[max_gene_id].values():\n",
    "                    out.write(key+'\\t'+'\\t'.join(record) + '\\n')\n",
    "            else:\n",
    "\n",
    "                for records in gene_groups.values():\n",
    "                    for record in records.values():\n",
    "                        out.write(key+'\\t'+'\\t'.join(record) + '\\n')\n",
    "\n",
    "    os.system('sort temp.tsv | uniq > ' + result_file)\n",
    "if __name__ == \"__main__\":\n",
    "    bed2tsv(\"res_gctemp.bed\", \"./test/map/res_gencode_map.tsv\")\n",
    "    bed2tsv(\"res_lctemp.bed\", \"./test/map/res_lncbook_map.tsv\")\n",
    "    bed2tsv(\"res_nctemp.bed\", \"./test/map/res_noncode_map.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in new match data: 4904\n",
      "Number of new targets: 209\n",
      "Checking gene_id conflicts, only handling LOC/non-LOC mixed conflicts...\n",
      "Handled 1 LOC/non-LOC mixed conflicts\n",
      "✓ LOC conflict resolution report saved: loc_gene_conflict_resolution.csv\n",
      "Calculating best gene mapping for each target (based on deduplicated exon cumulative length)...\n",
      "Number of target-gene combinations: 212\n",
      "✓ output: ./test/map/res_ncbi_map.tsv\n"
     ]
    }
   ],
   "source": [
    "!python3 pro1.py res_nbtemp.bed ./test/map/res_ncbi_map.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f temp.tsv res_lctemp.bed res_nctemp.bed res_gctemp.bed res_nbtemp.bed \n",
    "!rm -f ./test/output/lctemp.bed ./test/output/nctemp.bed ./test/output/gctemp.bed ./test/output/nbtemp.bed\n",
    "!rm -f filtered_lncbook_crispr.bed filtered_noncode_crispr.bed filtered_gencode_crispr.bed filtered_ncbi_crispr.bed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code is verification test code and can be not executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary verification code\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def  bed2tsv_temp(input_temp_bed_file, output_file):\n",
    "    \"\"\"\n",
    "    Convert a temporary BED file to a TSV file with specific fields.\n",
    "    \"\"\"\n",
    "    groups = defaultdict(set)  # 使用set自动去重\n",
    "    \n",
    "    with open(input_temp_bed_file, 'r') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) >= 15:\n",
    "                key = fields[3].rsplit('-', 1)[0]\n",
    "                transcript_id = fields[3].rsplit('-', 1)[1]\n",
    "                value = (transcript_id, fields[9], fields[12], fields[14])\n",
    "                \n",
    "                groups[key].add(value)  # set自动去重\n",
    "    \n",
    "    with open(output_file, 'w') as out:\n",
    "        for group_id, values in groups.items():\n",
    "            for value in values:\n",
    "                out.write(f'{group_id}\\t{value[0]}\\t{value[1]}\\t{value[2]}\\t{value[3]}\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bed2tsv_temp(\"./test/output/gctemp.bed\", \"./test/map/gcmap.tsv\")\n",
    "    bed2tsv_temp(\"./test/output/lctemp.bed\", \"./test/map/lcmap.tsv\")\n",
    "    bed2tsv_temp(\"./test/output/nctemp.bed\", \"./test/map/ncmap.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the deduplication process,if multiple gene IDs are matched,manually select the one with the highest overlap ratio.\n",
    "from collections import defaultdict\n",
    "\n",
    "input_temp_tsv_file = './test/map/gcmap.tsv'\n",
    "groups = defaultdict(set)\n",
    "\n",
    "\n",
    "with open(input_temp_tsv_file, 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        if len(fields) >= 5:\n",
    "            group_key = fields[0]  \n",
    "            gene_id = fields[3]    \n",
    "            groups[group_key].add(gene_id)\n",
    "\n",
    "\n",
    "with open('tocheck_id.txt', 'a') as out:\n",
    "    for group_key, gene_ids in groups.items():\n",
    "        if len(gene_ids) > 1:\n",
    "            out.write(f\"{group_key}\\t{','.join(gene_ids)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
